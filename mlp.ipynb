{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5VzgEXa1G4g"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%mkdir logs\n",
    "#!wget http://files.fast.ai/data/examples/dogscats.tgz  # Possibly later\n",
    "#!tar xzf dogscats.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQjVO7Xm0Qet"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MLP on {digits or faces or wine or dogs/cats} datasets\n",
    "JJV for Deep Learning course, 2022\n",
    "\"\"\"\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.datasets import fetch_lfw_people, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler  # Possibly later\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.manifold import TSNE  # Possibly later\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm  # Nice progress bars\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# DATA = 'digits'\n",
    "DATA = 'wine'\n",
    "# DATA = 'faces'\n",
    "# DATA = 'catsdogs'\n",
    "N_EPOCHS = 10  # if DATA == 'catsdogs' else 50\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 100\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "TIME = datetime.now().strftime(\"%Hh%Mm%Ss\")\n",
    "\n",
    "\n",
    "def preprocess_data():\n",
    "    '''\n",
    "    Prepare datasets.\n",
    "    Perform various operations (matrix rotation, normalization),\n",
    "    then split into train and test datasets.\n",
    "    Returns iterators over train and test.\n",
    "    '''\n",
    "    if DATA == 'catsdogs':\n",
    "        data_transform = transforms.Compose([\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        train_dataset = datasets.ImageFolder(\n",
    "            root='dogscats/train', transform=data_transform)\n",
    "        test_dataset = datasets.ImageFolder(\n",
    "            root='dogscats/valid', transform=data_transform)\n",
    "        # plt.imshow(train_dataset[0][0].permute(1, 2, 0).numpy())  # Display\n",
    "        # plt.show()\n",
    "        input_shape = (3, 224, 224)\n",
    "    else:\n",
    "        if DATA == 'faces':\n",
    "            faces = fetch_lfw_people(min_faces_per_person=70, color=True)\n",
    "            # plt.imshow(faces.images[0])  # Display one image\n",
    "            # plt.show()\n",
    "            X = torch.Tensor(faces.images).permute(0, 3, 1, 2)\n",
    "            y = torch.LongTensor(faces.target)\n",
    "            input_shape = (3, 62, 47)\n",
    "        elif DATA == 'digits':\n",
    "            digits = load_digits()\n",
    "            X = torch.Tensor(digits.images)\n",
    "            y = torch.LongTensor(digits.target)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, shuffle=True)\n",
    "            train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "            test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "            input_shape = (8, 8)\n",
    "        elif DATA == 'wine':\n",
    "            wine = pd.read_csv('winequality-red.csv')\n",
    "            X_raw = wine.drop(columns='quality').to_numpy()\n",
    "            # scaler = MinMaxScaler()\n",
    "            X = torch.Tensor(X_raw)\n",
    "            y = torch.LongTensor(wine['quality'])\n",
    "            input_shape = (11,)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, shuffle=True)\n",
    "        train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "        test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=100)\n",
    "    return X_train, y_train, X_test, y_test, train_iter, test_iter, input_shape\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multilayer perceptron.\n",
    "    Takes as argument:\n",
    "    - input_shape: the shape of each sample given as input\n",
    "    - dimensions: a list describing the number of neurons in each layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, dimensions: List[int]):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        layers = [nn.Flatten()]  # Flattens the input into 2-dim tensor: batches x features\n",
    "        sizes = [np.prod(self.input_shape)] + dimensions\n",
    "        for i in range(len(sizes) - 1):\n",
    "            # Your code here for adding layers according to the dimensions parameter\n",
    "            # Do not forget ReLU layers\n",
    "            layers.append(...)\n",
    "        self.fully_connected_layers = nn.Sequential(*layers)\n",
    "        # the '*' before 'layers' is to transform a list into several arguments\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.fully_connected_layers(x)\n",
    "        return logits\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{DATA}-mlp-{'-'.join(map(str, dimensions))}\"  # e.g. mlp-32-10\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_function, optimizer, writer):\n",
    "    model.train()  # Training mode\n",
    "    losses = []\n",
    "    accuracies = [0.]\n",
    "    for inputs, targets in tqdm(dataloader):\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        writer.add_graph(model, inputs)  # Display graph in TensorBoard\n",
    "        # writer.add_images('images', inputs)  # Display images in TensorBoard\n",
    "\n",
    "        # Compute prediction error\n",
    "        logits = model(inputs)\n",
    "        loss = loss_function(logits, targets)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predictions = logits.argmax(axis=1)\n",
    "        accuracies.append(torch.sum(predictions == targets).item())\n",
    "\n",
    "        losses.append(loss.item())\n",
    "    return np.mean(losses), np.sum(accuracies) / len(dataloader.dataset)\n",
    "\n",
    "\n",
    "def test(dataloader, model):\n",
    "    model.eval()  # Test mode\n",
    "    accuracies = []\n",
    "    with torch.no_grad():  # No training\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "\n",
    "            logits = model(inputs)\n",
    "            predictions = logits.argmax(axis=1)\n",
    "            accuracies.append(torch.sum(predictions == targets).item())\n",
    "    return np.sum(accuracies) / len(dataloader.dataset)\n",
    "\n",
    "\n",
    "def plot_2d(matrix, colors):\n",
    "    \"\"\"\n",
    "    Projecting along the first two principal components (having largest eigenvalue)\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(matrix)\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=colors, marker='.')\n",
    "\n",
    "\n",
    "def plot_tsne(matrix, colors):\n",
    "    \"\"\"\n",
    "    Non-linear projection called t-distributed stochastic neighbor embedding (t-SNE).\n",
    "    \"\"\"\n",
    "    tsne = TSNE()\n",
    "    X_tsne = tsne.fit_transform(matrix)\n",
    "    plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=colors, marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N7val-lDT9-a"
   },
   "outputs": [],
   "source": [
    "%rm -rf logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHcqkB1004A_"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, train_iter, test_iter, input_shape = preprocess_data()\n",
    "\n",
    "dimensions = [10]  # Number of neurons for each layer\n",
    "model = MLP(input_shape, dimensions).to(DEVICE)\n",
    "print(model.fully_connected_layers)\n",
    "writer = SummaryWriter(log_dir=f'logs/fit/{model}-{TIME}')  # TBoard\n",
    "\n",
    "n_parameters = 0\n",
    "for name, parameter in model.named_parameters():\n",
    "    print(name, parameter.numel())\n",
    "    n_parameters += parameter.numel()\n",
    "print(f'Total number of parameters of {model}: {n_parameters}')\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in tqdm(range(N_EPOCHS)):\n",
    "    print(f'=== Epoch {epoch} ===')\n",
    "    train_loss, train_acc = train(train_iter, model, loss_function,\n",
    "                                  optimizer, writer)\n",
    "    print(f'Train loss: {train_loss:7f} / Train acc: {train_acc:.2f}')\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "\n",
    "    test_acc = test(test_iter, model)\n",
    "    print(f'Test accuracy: {test_acc:.2f}')\n",
    "    writer.add_scalar('Accuracy/test', test_acc, epoch)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X_test)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d(X_train.reshape(-1, np.prod(input_shape)), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LE3zOOBv0VBv"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input_, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model.fully_connected_layers._modules['1'].register_forward_hook(get_activation('hidden'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.forward(X_train)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d(logits.detach(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation['hidden'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d(activation['hidden'], y_train)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
